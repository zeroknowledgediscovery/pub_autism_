\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\Newlabel{cor1}{1}
\providecommand \oddpage@label [2]{}
\Newlabel{ad1}{a}
\Newlabel{ad2}{b}
\Newlabel{ad3}{c}
\Newlabel{ad4}{d}
\Newlabel{ad5}{e}
\Newlabel{ad6}{f}
\Newlabel{ad7}{g}
\citation{pmid31562252}
\citation{pmid31562252}
\gdef \LT@i {\LT@entry 
    {4}{16.4137pt}\LT@entry 
    {1}{50.93498pt}\LT@entry 
    {1}{427.95248pt}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Disease Categories With Detailed Set of ICD9 Codes Used }}{3}{table.1}}
\newlabel{tab0}{{1}{3}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Disease Categories With Detailed Set of ICD9 Codes Used}{table.1}{}}
\citation{ltgranger80}
\citation{CL12g}
\citation{GEMS}
\citation{Cover,kullback1951}
\citation{doob1953stochastic}
\@writefile{toc}{\contentsline {section}{\numberline {1}Detailed Mathematical Approach}{9}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Time-series Modeling of Diagnostic History}{9}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Step 1: Partitioning The Human Disease Spectrum}{9}{subsection.1.2}}
\newlabel{eq1}{{1}{9}{Step 1: Partitioning The Human Disease Spectrum}{equation.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Step 2: Model Inference \& The Sequence Likelihood Defect}{9}{subsection.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Probabilistic Finite State Automata models generated for different disease categories for the control and positive\xspace  cohorts. We note that in the first cases (digestive disorder), the models get more complex in the positive\xspace  cohort, suggesting that the disorders become less random. However, in the categories of otic and integumentary disorders, the models become less complex suggesting increased independence from past events of similat nature. In case of infectious diseases, the model gets more complex for males, and less complex for females, suggesting distinct sex-specific responses associated with high ASD risk. }}{10}{figure.1}}
\newlabel{EXT-autgrid}{{1}{10}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Probabilistic Finite State Automata models generated for different disease categories for the control and \treatment cohorts. We note that in the first cases (digestive disorder), the models get more complex in the \treatment cohort, suggesting that the disorders become less random. However, in the categories of otic and integumentary disorders, the models become less complex suggesting increased independence from past events of similat nature. In case of infectious diseases, the model gets more complex for males, and less complex for females, suggesting distinct sex-specific responses associated with high ASD risk}{figure.1}{}}
\citation{Cover}
\citation{gbm02}
\citation{Breiman}
\citation{Friedman}
\citation{Hochreiter}
\newlabel{eqR}{{4}{11}{Step 2: Model Inference \& The Sequence Likelihood Defect}{equation.1.4}{}}
\newlabel{eq6}{{5}{11}{Step 2: Model Inference \& The Sequence Likelihood Defect}{equation.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Step 3: Risk Estimation Pipeline With Semi-supervised \& Supervised Learning Modules}{11}{subsection.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Comparison With State of the Art Off-the-shelf ML Algorithms}{11}{section.2}}
\newlabel{sec:offtheshelf}{{2}{11}{Comparison With State of the Art Off-the-shelf ML Algorithms}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Comparison With Pipeline Variations, Feature Subsets and Neural Net Post-processing}{11}{section.3}}
\newlabel{sec:pipelinevar}{{3}{11}{Comparison With Pipeline Variations, Feature Subsets and Neural Net Post-processing}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Performance of standard tools on correctly predicting eventual ASD diagnosis, computed at age $150$ weeks of age. Long-short Term Memory (LSTM) networks are the state of the art variation of recurrent neural nets, and Random Forests and Gradient Boosting classifiers (CatBoost) are generally regarded as a representative state of the art classification algorithms. Sequence Likelihood Defect (SLD) is the approach developed in this study. LSTMB denotes LSTM with identical pre-processing as in our pipeline (instead of using raw diagnostic codes). We get much better performance with LSTMB with males in the Truven dataset, but the performance is sensitive to the sizes of the training set, and degrades for smaller samples available for females and in the UCM database, as shown in Panel B. }}{12}{figure.2}}
\newlabel{EXT-figcompwsoa}{{2}{12}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Performance of standard tools on correctly predicting eventual ASD diagnosis, computed at age $150$ weeks of age. Long-short Term Memory (LSTM) networks are the state of the art variation of recurrent neural nets, and Random Forests and Gradient Boosting classifiers (CatBoost) are generally regarded as a representative state of the art classification algorithms. Sequence Likelihood Defect (SLD) is the approach developed in this study. LSTMB denotes LSTM with identical pre-processing as in our pipeline (instead of using raw diagnostic codes). We get much better performance with LSTMB with males in the Truven dataset, but the performance is sensitive to the sizes of the training set, and degrades for smaller samples available for females and in the UCM database, as shown in Panel B}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  \textbf  {Evaluations of Feature Subsets, Class Imbalance, Code Density, Coding Uncertainty, \& Disambiguation from Other Psychiatric Phenotypes.} Panel A illustrates that the pipeline performance where the control group is restricted to children to have at least one psychiatric phenotype other than ASD. It is clear that we have very good discrimination between ASD and non-ASD phenotypes. Panel B illustrates the situation where we restrict the treatment cohort to children to have at least $2$ AD diagnostic codes, to see whether the pipeline performance is markedly different in populations where the coding errors/uncertainty is smaller. We see that such restrictions have no appreciable effect on pipeline performance. Panel C illustrates the AUC distributions obtained by using sampled control cohorts that are of the same size as the treatment cohort, to evaluate the effect of class imbalance. Again we see that such restrictions do not appreciably change performance. Panel D explores the performance changes when we use a restricted set of features, or simply use code density as the sole feature. We conclude that the combined feature set used in our optimized pipeline is superior to using the subsets individually. Code density is the least performant feature, and is not stable across databases.  }}{13}{figure.3}}
\newlabel{EXT-figcompsi}{{3}{13}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont \textbf {Evaluations of Feature Subsets, Class Imbalance, Code Density, Coding Uncertainty, \& Disambiguation from Other Psychiatric Phenotypes.} Panel A illustrates that the pipeline performance where the control group is restricted to children to have at least one psychiatric phenotype other than ASD. It is clear that we have very good discrimination between ASD and non-ASD phenotypes. Panel B illustrates the situation where we restrict the treatment cohort to children to have at least $2$ AD diagnostic codes, to see whether the pipeline performance is markedly different in populations where the coding errors/uncertainty is smaller. We see that such restrictions have no appreciable effect on pipeline performance. Panel C illustrates the AUC distributions obtained by using sampled control cohorts that are of the same size as the treatment cohort, to evaluate the effect of class imbalance. Again we see that such restrictions do not appreciably change performance. Panel D explores the performance changes when we use a restricted set of features, or simply use code density as the sole feature. We conclude that the combined feature set used in our optimized pipeline is superior to using the subsets individually. Code density is the least performant feature, and is not stable across databases}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Feature Subset Evaluations \& Code Density As A Feature}{13}{subsection.3.1}}
\newlabel{subsec:features}{{3.1}{13}{Feature Subset Evaluations \& Code Density As A Feature}{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  \textbf  {Details of Co-morbidity Patterns (at age $<3$ years)} for immunologic (panel A), respiratory (panel B), infections (panel C), and disorders with similar pathobiology manifesting opposing association with autism (panel D). }}{14}{figure.4}}
\newlabel{EXT-fig4}{{4}{14}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont \textbf {Details of Co-morbidity Patterns (at age $<3$ years)} for immunologic (panel A), respiratory (panel B), infections (panel C), and disorders with similar pathobiology manifesting opposing association with autism (panel D)}{figure.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Threshold Selection on ROC Curve}{14}{section.4}}
\newlabel{sec:F1}{{4}{14}{Threshold Selection on ROC Curve}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  \textbf  {Co-morbidity Patterns} for mental disorders, vaccinations and health-service encounters. }}{15}{figure.5}}
\newlabel{EXT-figvv1}{{5}{15}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont \textbf {Co-morbidity Patterns} for mental disorders, vaccinations and health-service encounters}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Predictive Performance without psychiatric codes (ICD9 290 - 319) and codes for health status and services (ICD9 V0-V91) included. As shown, the performance is comparable at 150 weeks, with the AUC for females marginally lower (compare with Fig.\nobreakspace  {}\ref  {main-fig1} in the main text). The feature importances also are similar, with infectious diseases inferred to have the most importance (or weight) in the pipeline, which is also the case once we add psychiatric phenotypes, and codes for health services in our analysis. As shown in Fig.\nobreakspace  {}\ref  {EXT-figvv1}A, the psychiatric codes all increase risk, and the vaccination codes (See Fig.\nobreakspace  {}\ref  {EXT-figvv1}B) all decrease risk when those codes are included. This is why an alternate analysis was carried out to make sure that we are not picking up on psychiatric codes alone. Note in particular that the sensitivity/specificity point highlighted in panel A above is identical after adding the codes. This suggests that our predictive performance arises from patterns learned from co-morbidities, which are not just neuropsychiatric in nature. }}{16}{figure.6}}
\newlabel{EXT-fig1nop}{{6}{16}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Predictive Performance without psychiatric codes (ICD9 290 - 319) and codes for health status and services (ICD9 V0-V91) included. As shown, the performance is comparable at 150 weeks, with the AUC for females marginally lower (compare with Fig.~\ref {main-fig1} in the main text). The feature importances also are similar, with infectious diseases inferred to have the most importance (or weight) in the pipeline, which is also the case once we add psychiatric phenotypes, and codes for health services in our analysis. As shown in Fig.~\ref {EXT-figvv1}A, the psychiatric codes all increase risk, and the vaccination codes (See Fig.~\ref {EXT-figvv1}B) all decrease risk when those codes are included. This is why an alternate analysis was carried out to make sure that we are not picking up on psychiatric codes alone. Note in particular that the sensitivity/specificity point highlighted in panel A above is identical after adding the codes. This suggests that our predictive performance arises from patterns learned from co-morbidities, which are not just neuropsychiatric in nature}{figure.6}{}}
\citation{pmid31562252}
\@writefile{toc}{\contentsline {section}{\numberline {5}Note on Reciever Operating Characteristics (ROC) and Precision-recall Curves}{17}{section.5}}
\newlabel{sec:ROC}{{5}{17}{Note on Reciever Operating Characteristics (ROC) and Precision-recall Curves}{section.5}{}}
\newlabel{eq9}{{14}{17}{Note on Reciever Operating Characteristics (ROC) and Precision-recall Curves}{equation.5.14}{}}
\newlabel{eqPPV}{{15}{17}{Note on Reciever Operating Characteristics (ROC) and Precision-recall Curves}{equation.5.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Effect of Class Imbalance}{17}{section.6}}
\newlabel{subsec:classimbalance}{{6}{17}{Effect of Class Imbalance}{section.6}{}}
\citation{gordon2016whittling,penner2018practice,hyman2020identification}
\citation{johnson2007identification,zwaigenbaum2015early}
\citation{robins2014validation,hyman2020identification}
\citation{hyman2020identification}
\citation{penner2018practice}
\citation{hyman2020identification}
\citation{esler2015autism}
\citation{chlebowski2010using}
\citation{hyman2020identification}
\citation{falkmer2013diagnostic}
\citation{falkmer2013diagnostic}
\citation{falkmer2013diagnostic}
\@writefile{toc}{\contentsline {section}{\numberline {7}Note on ASD Clinical Diagnosis \& Uncertainty of EHR Record}{18}{section.7}}
\newlabel{sec:diag}{{7}{18}{Note on ASD Clinical Diagnosis \& Uncertainty of EHR Record}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Diagnostic Evaluations}{18}{subsection.7.1}}
\newlabel{subsec:diageval}{{7.1}{18}{Diagnostic Evaluations}{subsection.7.1}{}}
\citation{hyman2020identification}
\citation{robins2014validation,hyman2020identification}
\citation{pmid31562252}
\citation{hyman2020identification}
\citation{hyman2020identification}
\citation{pmid31562252}
\citation{lord2006autism,kleinman2008diagnostic}
\citation{bolton2012autism,kozlowski2011parents}
\citation{baio2014prevalence}
\citation{kalb2012determinants}
\citation{bisgaier2011access}
\citation{fenikile2015barriers}
\citation{fenikile2015barriers}
\citation{gordon2016whittling}
\citation{gordon2016whittling,althouse2006pediatric}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Change In Diagnostic Criteria for ASD, Inclusion of PDD, Asperger, and Disambiguation From Unrelated Psychiatric Phenotypes}{19}{subsection.7.2}}
\newlabel{subsec:otherpsych}{{7.2}{19}{Change In Diagnostic Criteria for ASD, Inclusion of PDD, Asperger, and Disambiguation From Unrelated Psychiatric Phenotypes}{subsection.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Performance Comparison With M-CHAT/F}{19}{subsection.7.3}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Improving Wait-times For Diagnostic Evaluations by Reducing False Positives in Routine Screening}{19}{section.8}}
\newlabel{sec:waittime}{{8}{19}{Improving Wait-times For Diagnostic Evaluations by Reducing False Positives in Routine Screening}{section.8}{}}
\citation{pmid31562252}
\citation{pmid31562252}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  \textbf  {4D Search To Take Advantage of Data on Population Stratification (Using Prevalence of 2.23\% as reported by CHOP\nobreakspace  {}\cite  {pmid31562252}).} While as a standalone tool our approach is comparable to M-CHAT/F at around the 26 month mark (and later), we can take advantage of the independence of the tests to devise a conditional choice of the operating parameters for the new approach. In particular, taking advantage of published estimated prevalence rates of different categories of M-CHAT/F scores, and true positives in each sub-population upon stratification, we can choose a different set of specificity and sensitivity in each sub-population to yield significantly improved overall performance across databases, and much earlier. Additionally, we can choose to operate at a high recall point, where we maximize overall sensitivity, or a high precision point, where we maximize the positive predictive value. }}{20}{figure.7}}
\newlabel{EXT-fig4D}{{7}{20}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont \textbf {4D Search To Take Advantage of Data on Population Stratification (Using Prevalence of 2.23\% as reported by CHOP~\cite {pmid31562252}).} While as a standalone tool our approach is comparable to M-CHAT/F at around the 26 month mark (and later), we can take advantage of the independence of the tests to devise a conditional choice of the operating parameters for the new approach. In particular, taking advantage of published estimated prevalence rates of different categories of M-CHAT/F scores, and true positives in each sub-population upon stratification, we can choose a different set of specificity and sensitivity in each sub-population to yield significantly improved overall performance across databases, and much earlier. Additionally, we can choose to operate at a high recall point, where we maximize overall sensitivity, or a high precision point, where we maximize the positive predictive value}{figure.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}4D Decision Optimization Using M-CHAT/F Population Stratification To Boost PPV}{20}{subsection.8.1}}
\newlabel{subsec:4D}{{8.1}{20}{4D Decision Optimization Using M-CHAT/F Population Stratification To Boost PPV}{subsection.8.1}{}}
\newlabel{eqscpop}{{22}{20}{4D Decision Optimization Using M-CHAT/F Population Stratification To Boost PPV}{equation.8.22}{}}
\citation{pmid31562252}
\citation{pmid31562252}
\citation{pmid31562252}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Boosted Sensitivity, Specificity and PPV Achieved at \textbf  {150 weeks} Conditioned on M-CHAT/F Scores }}{21}{table.2}}
\newlabel{EXT-tabboost150}{{2}{21}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Boosted Sensitivity, Specificity and PPV Achieved at \textbf {150 weeks} Conditioned on M-CHAT/F Scores}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Population Stratification Results on large M-CHAT/F Study(n=20,375)\nobreakspace  {}\cite  {pmid31562252}  }}{21}{table.3}}
\newlabel{EXT-tabCHOP}{{3}{21}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Population Stratification Results on large M-CHAT/F Study(n=20,375)~\cite {pmid31562252}}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  $\gamma ,\gamma '$ Computed from Population Stratification Recorded In M-CHAT/F Study\nobreakspace  {}\cite  {pmid31562252} ($\rho =0.0223$)  }}{21}{table.4}}
\newlabel{EXT-tabCHOP2}{{4}{21}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont $\gamma ,\gamma '$ Computed from Population Stratification Recorded In M-CHAT/F Study~\cite {pmid31562252} ($\rho =0.0223$)}{table.4}{}}
\citation{hyman2020identification}
\citation{pmid31562252}
\citation{CL12g}
\citation{hopcroft2008introduction}
\citation{klenke2013probability}
\citation{doob1990stochastic}
\citation{klenke2013probability}
\@writefile{toc}{\contentsline {section}{\numberline {9}Generating PFSA Models From Set of Input Streams with Variable Input Lengths}{22}{section.9}}
\newlabel{sec:varl}{{9}{22}{Generating PFSA Models From Set of Input Streams with Variable Input Lengths}{section.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Probabilsitic Finite State Automata Inference}{22}{section.10}}
\newlabel{sec:PFSA}{{10}{22}{Probabilsitic Finite State Automata Inference}{section.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Probabilistic Finite-State Automaton}{22}{subsection.10.1}}
\newlabel{subsec:DEFN_PFSA}{{10.1}{22}{Probabilistic Finite-State Automaton}{subsection.10.1}{}}
\newlabel{defn:StochasticProcessOverSigma}{{2}{22}{Stochastic Process over $\Sigma $}{defn.2}{}}
\newlabel{defn:MeasureAndDeriv}{{3}{22}{Sequence-Induced Measure and Derivative}{defn.3}{}}
\citation{chattopadhyay2008structural}
\citation{chattopadhyay2014data}
\citation{bondy2008graph}
\citation{vidyasagar2014hidden,kai1967markov_StDis}
\newlabel{defn:NerodeEquiv}{{4}{23}{Probabilistic Nerode Equivalence and Causal States \cite {chattopadhyay2008structural}}{defn.4}{}}
\newlabel{defn:PFSA}{{5}{23}{Probabilistic Finite-State Automaton (PFSA)}{defn.5}{}}
\newlabel{defn:StrongConn}{{8}{23}{Strongly Connected PFSA}{defn.8}{}}
\newlabel{defn:GammaExpr}{{9}{23}{$\Gamma $-Expression}{defn.9}{}}
\newlabel{defn:InducedDistr}{{10}{23}{Sequence-Induced Distribution on States}{defn.10}{}}
\newlabel{defn:StochasticProcessOfPFSA}{{11}{23}{Stochastic Process Generated by a PFSA}{defn.11}{}}
\citation{trahtman2008road}
\citation{cover2012elements}
\citation{matthews2016sparse}
\newlabel{def:JointSyncSeq}{{15}{24}{Joint $\varepsilon $-Synchronizing Sequence}{defn.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Sequence Likelihood Defect}{24}{section.11}}
\newlabel{sec:SLD}{{11}{24}{Sequence Likelihood Defect}{section.11}{}}
\newlabel{thm:Closed-formFormulaForEntropyRate}{{1}{24}{Closed-form Formula for Entropy Rate and KL Divergence}{thm.1}{}}
\citation{cover2012elements}
\newlabel{alg:GenL}{{1}{25}{Probabilistic Finite-State Automaton}{AlgoLine.1.1}{}}
\newlabel{alg:GenConv}{{3}{25}{Probabilistic Finite-State Automaton}{AlgoLine.1.3}{}}
\newlabel{alg:GenSyncSeq}{{4}{25}{Probabilistic Finite-State Automaton}{AlgoLine.1.4}{}}
\newlabel{alg:GenStep2Start}{{5}{25}{Probabilistic Finite-State Automaton}{AlgoLine.1.5}{}}
\newlabel{alg:GenIdenStateStart}{{12}{25}{Probabilistic Finite-State Automaton}{AlgoLine.1.12}{}}
\newlabel{alg:GenIdenStateEnd}{{17}{25}{Probabilistic Finite-State Automaton}{AlgoLine.1.17}{}}
\newlabel{alg:GenStep2End}{{19}{25}{Probabilistic Finite-State Automaton}{AlgoLine.1.19}{}}
\newlabel{alg:GenIdenTransProbStart}{{20}{25}{Probabilistic Finite-State Automaton}{AlgoLine.1.20}{}}
\newlabel{alg:GenIdenTransProbEnd}{{25}{25}{Probabilistic Finite-State Automaton}{AlgoLine.1.25}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces \textrm  {\bf  \texttt  {GenESeSS}}\xspace  }}{25}{algocf.1}}
\newlabel{alg:GenESeSS}{{1}{25}{Probabilistic Finite-State Automaton}{algocf.1}{}}
\newlabel{thm:convergenceOfLLH}{{2}{25}{Convergence of log-likelihood}{thm.2}{}}
\citation{hardy1992divergent}
\citation{CL12g}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Log-likelihood}}{26}{algocf.2}}
\newlabel{alg:LLK}{{2}{26}{Sequence Likelihood Defect}{algocf.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12}Pipeline Optimization}{26}{section.12}}
\newlabel{sec:pipeline}{{12}{26}{Pipeline Optimization}{section.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}Input Data Format}{26}{subsection.12.1}}
\citation{CL12g}
\citation{CL12g}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces ICD-9 Encoding}}{27}{algocf.3}}
\newlabel{algo1}{{3}{27}{Input Data Format}{algocf.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2}Algorithms}{27}{subsection.12.2}}
\@writefile{toc}{\contentsline {section}{\numberline {13}Example Run with Released Application}{27}{section.13}}
\newlabel{sec:app}{{13}{27}{Example Run with Released Application}{section.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1}Prerequisites \& Installation}{27}{subsection.13.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2}EHR data format}{27}{subsection.13.2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Prediction Pipeline Training}}{28}{algocf.4}}
\newlabel{algo2}{{4}{28}{Input Data Format}{algocf.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3}Sample Python code risk estimation}{28}{subsection.13.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4}Sample Python script risk estimation}{28}{subsection.13.4}}
\bibstyle{naturemag}
\bibdata{aut,BibLib1,SIbib.bib,bibliography,PFSAThm}
\bibcite{pmid31562252}{{1}{}{{}}{{}}}
\bibcite{ltgranger80}{{2}{}{{}}{{}}}
\bibcite{CL12g}{{3}{}{{}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Pipeline schema: How the data set is split into test sets and two training sets: one for inferring HMM models, and one for training the boosting classifier. The two ket algorithms here are \texttt  {genESeSS}\nobreakspace  {}\cite  {CL12g} and the llk which does the sequence likelihood computation described in Section\nobreakspace  {}\ref  {sec:SLD} }}{29}{figure.8}}
\newlabel{figschema}{{8}{29}{\color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Pipeline schema: How the data set is split into test sets and two training sets: one for inferring HMM models, and one for training the boosting classifier. The two ket algorithms here are \texttt {genESeSS}~\cite {CL12g} and the llk which does the sequence likelihood computation described in Section~\ref {sec:SLD}}{figure.8}{}}
\bibcite{GEMS}{{4}{}{{}}{{}}}
\bibcite{Cover}{{5}{}{{}}{{}}}
\bibcite{kullback1951}{{6}{}{{}}{{}}}
\bibcite{doob1953stochastic}{{7}{}{{}}{{}}}
\bibcite{gbm02}{{8}{}{{}}{{}}}
\bibcite{Breiman}{{9}{}{{}}{{}}}
\bibcite{Friedman}{{10}{}{{}}{{}}}
\bibcite{Hochreiter}{{11}{}{{}}{{}}}
\bibcite{gordon2016whittling}{{12}{}{{}}{{}}}
\bibcite{penner2018practice}{{13}{}{{}}{{}}}
\bibcite{hyman2020identification}{{14}{}{{}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Screen capture of the page on pypi.org hosting the released application Link: \href  {hhtp://pypi.org/ehrzero}{http://pypi.org/ehrzero} }}{30}{figure.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Python code prediction example }}{30}{figure.10}}
\bibcite{johnson2007identification}{{15}{}{{}}{{}}}
\bibcite{zwaigenbaum2015early}{{16}{}{{}}{{}}}
\bibcite{robins2014validation}{{17}{}{{}}{{}}}
\bibcite{esler2015autism}{{18}{}{{}}{{}}}
\bibcite{chlebowski2010using}{{19}{}{{}}{{}}}
\bibcite{falkmer2013diagnostic}{{20}{}{{}}{{}}}
\bibcite{lord2006autism}{{21}{}{{}}{{}}}
\bibcite{kleinman2008diagnostic}{{22}{}{{}}{{}}}
\bibcite{bolton2012autism}{{23}{}{{}}{{}}}
\bibcite{kozlowski2011parents}{{24}{}{{}}{{}}}
\bibcite{baio2014prevalence}{{25}{}{{}}{{}}}
\bibcite{kalb2012determinants}{{26}{}{{}}{{}}}
\bibcite{bisgaier2011access}{{27}{}{{}}{{}}}
\bibcite{fenikile2015barriers}{{28}{}{{}}{{}}}
\bibcite{althouse2006pediatric}{{29}{}{{}}{{}}}
\bibcite{hopcroft2008introduction}{{30}{}{{}}{{}}}
\bibcite{klenke2013probability}{{31}{}{{}}{{}}}
\bibcite{doob1990stochastic}{{32}{}{{}}{{}}}
\bibcite{chattopadhyay2008structural}{{33}{}{{}}{{}}}
\bibcite{chattopadhyay2014data}{{34}{}{{}}{{}}}
\bibcite{bondy2008graph}{{35}{}{{}}{{}}}
\bibcite{vidyasagar2014hidden}{{36}{}{{}}{{}}}
\bibcite{kai1967markov_StDis}{{37}{}{{}}{{}}}
\bibcite{trahtman2008road}{{38}{}{{}}{{}}}
\bibcite{cover2012elements}{{39}{}{{}}{{}}}
\bibcite{matthews2016sparse}{{40}{}{{}}{{}}}
\bibcite{hardy1992divergent}{{41}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \color  {CadetBlue4!80!black} \sffamily  \fontsize  {9}{10}\selectfont  Python script prediction example }}{31}{figure.11}}
