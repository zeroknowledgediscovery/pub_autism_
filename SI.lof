\contentsline {figure}{\numberline {1}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont \textbf {Details of Co-morbidity Patterns (at age $<3$ years)} for immunologic (panel A), respiratory (panel B), infections (panel C), and disorders with similar pathobiology manifesting opposing association with autism (panel D). }}{5}{figure.1}
\contentsline {figure}{\numberline {2}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont \textbf {Co-morbidity Patterns} for mental disorders, vaccinations and health-service encounters. }}{6}{figure.2}
\contentsline {figure}{\numberline {3}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Performance of standard tools on correctly predicting eventual ASD diagnosis, computed at age $150$ weeks of age. Long-short Term Memory (LSTM) networks are the state of the art variation of recurrent neural nets, and Random Forests and Gradient Boosting classifiers (CatBoost) are generally regarded as a representative state of the art classification algorithms. Sequence Likelihood Defect (SLD) is the approach developed in this study. LSTMB denotes LSTM with identical pre-processing as in our pipeline (instead of using raw diagnostic codes). We get much better performance with LSTMB with males in the Truven dataset, but the performance is sensitive to the sizes of the training set, and degrades for smaller samples available for females and in the UCM database, as shown in Panel B. }}{7}{figure.3}
\contentsline {figure}{\numberline {4}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont \textbf {4D Search To Take Advantage of Data on Population Stratification (Using Prevalence of 2.23\% as reported by CHOP\nobreakspace {}\cite {pmid31562252}).} While as a standalone tool our approach is comparable to M-CHAT/F at around the 26 month mark (and later), we can take advantage of the independence of the tests to devise a conditional choice of the operating parameters for the new approach. In particular, taking advantage of published estimated prevalence rates of different categories of M-CHAT/F scores, and true positives in each sub-population upon stratification, we can choose a different set of specificity and sensitivity in each sub-population to yield significantly improved overall performance across databases, and much earlier. Additionally, we can choose to operate at a high recall point, where we maximize overall sensitivity, or a high precision point, where we maximize the positive predictive value. }}{7}{figure.4}
\contentsline {figure}{\numberline {5}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont \textbf {Evaluations of Feature Subsets, Class Imbalance, Code Density, Coding Uncertainty, \& Disambiguation from Other Psychiatric Phenotypes.} Panel A illustrates that the pipeline performance where the control group is restricted to children to have at least one psychiatric phenotype other than ASD. It is clear that we have very good discrimination between ASD and non-ASD phenotypes. Panel B illustrates the situation where we restrict the treatment cohort to children to have at least $2$ AD diagnostic codes, to see whether the pipeline performance is markedly different in populations where the coding errors/uncertainty is smaller. We see that such restrictions have no appreciable effect on pipeline performance. Panel C illustrates the AUC distributions obtained by using sampled control cohorts that are of the same size as the treatment cohort, to evaluate the effect of class imbalance. Again we see that such restrictions do not appreciably change performance. Panel D explores the performance changes when we use a restricted set of features, or simply use code density as the sole feature. We conclude that the combined feature set used in our optimized pipeline is superior to using the subsets individually. Code density is the least performant feature, and is not stable across databases. }}{8}{figure.5}
\contentsline {figure}{\numberline {6}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Predictive Performance without psychiatric codes (ICD9 290 - 319) and codes for health status and services (ICD9 V0-V91) included. As shown, the performance is comparable at 150 weeks, with the AUC for females marginally lower (compare with Fig.\nobreakspace {}\ref {fig1} in the main text). The feature importances also are similar, with infectious diseases inferred to have the most importance (or weight) in the pipeline, which is also the case once we add psychiatric phenotypes, and codes for health services in our analysis. As shown in Fig.\nobreakspace {}\ref {EXT-figvv1}A, the psychiatric codes all increase risk, and the vaccination codes (See Fig.\nobreakspace {}\ref {EXT-figvv1}B) all decrease risk when those codes are included. This is why an alternate analysis was carried out to make sure that we are not picking up on psychiatric codes alone. Note in particular that the sensitivity/specificity point highlighted in panel A above is identical after adding the codes. This suggests that our predictive performance arises from patterns learned from co-morbidities, which are not just neuropsychiatric in nature. }}{9}{figure.6}
\contentsline {figure}{\numberline {7}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Probabilistic Finite State Automata models generated for different disease categories for the control and positive\xspace cohorts. We note that in the first cases (digestive disorder), the models get more complex in the positive\xspace cohort, suggesting that the disorders become less random. However, in the categories of otic and integumentary disorders, the models become less complex suggesting increased independence from past events of similat nature. In case of infectious diseases, the model gets more complex for males, and less complex for females, suggesting distinct sex-specific responses associated with high ASD risk. }}{10}{figure.7}
\contentsline {figure}{\numberline {8}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Pipeline schema: How the data set is split into test sets and two training sets: one for inferring HMM models, and one for training the boosting classifier. The two ket algorithms here are \texttt {genESeSS}\nobreakspace {}\cite {CL12g} and the llk which does the sequence likelihood computation described in Section\nobreakspace {}\ref {sec:SLD} }}{20}{figure.8}
\contentsline {figure}{\numberline {9}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Screen capture of the page on pypi.org hosting the released application Link: \href {hhtp://pypi.org/ehrzero}{http://pypi.org/ehrzero} }}{21}{figure.9}
\contentsline {figure}{\numberline {10}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Python code prediction example }}{21}{figure.10}
\contentsline {figure}{\numberline {11}{\ignorespaces \color {CadetBlue4!80!black} \sffamily \fontsize {9}{10}\selectfont Python script prediction example }}{22}{figure.11}
